---
title: "Practical_Machine_Learning_proj"
author: "Bert"
date: "11/21/2015"
output: html_document
---
# Using Human Activity Data to Predict Dumbbell Lift Form

In this project our goal is to use Human Activity Data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 

More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 

The goal of the project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. 

## How the Model was Built

First let's load the training and test data:
```{r}
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv?accessType=DOWNLOAD"
download.file(fileUrl1,destfile = "pml-training.csv", method = "curl")
pml_training <- read.table("pml-training.csv", sep = ",", header = TRUE)
fileUrl2 <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv?accessType=DOWNLOAD"
download.file(fileUrl2,destfile = "pml-testing.csv", method = "curl")
pml_testing <- read.table("pml-testing.csv", sep = ",", header = TRUE)
```

From inspecting the raw .csv data file you can see that a number of the columns of types of data are very lightly populated, so those are right away dropped from the pool of useable data. This still leaves a lot of types of data that can be included. I then thought about the physical task in the study and what kinds of variables would be relevent, and went through a process of cylcing through doing Principal Component Analysis and running training tests on those components, adding and taking away columns of data, and then going back to doing Principal Components Analysis on the model that looks promising (based on the output of the model generated by the training function.)

I do not think that the Out of Sample Error would be large because the model does not use a lot of variables in the model and the fit with what I used was not as strong as I had hoped, so it seems very unlikely that the model is over-fitted to the trainging data, and overfit is the main source of Out of Sample Error.

Here is a Principal Components Analysis on the variables included in the model. This presents a set of the principal components needed to capture a good percentage of the variance.

```{r}
pml_train.pca <- prcomp(~ roll_belt + pitch_belt + yaw_belt + gyros_belt_x + gyros_belt_y + gyros_belt_z + roll_arm + pitch_arm + yaw_arm,data=pml_training,center = TRUE, scale. = TRUE)
summary(pml_train.pca)
```

The model I settled on was this:    
**classe ~ roll_belt + pitch_belt + yaw_belt + gyros_belt_x + gyros_belt_y + gyros_belt_z + roll_arm + pitch_arm + yaw_arm**

## The Model being Put Through Training, Cross-Validation, and Prediction

Here is the model I came up with being put through the Train function:

```{r}
set.seed(4567)
library("caret")
model.rpart <- train(classe ~ roll_belt + pitch_belt + yaw_belt + gyros_belt_x + gyros_belt_y + gyros_belt_z + roll_arm + pitch_arm + yaw_arm, data = pml_training,method="rpart")
model.rpart
```

Here is a print of the probability/decision tree. I find this feature of the Caret package to be interesting.
```{r}
print(model.rpart$finalModel)
```

Here is the model being put through cross validation through use of a Confusion Matrix:
```{r}
predictions_training <- predict(model.rpart,newdata=pml_training)
confusionMatrix(predictions_training,pml_training$classe)
```

Finally, here is the model being applied to generate predictions on the 20 different test cases:
```{r}
predictions_testing <- predict(model.rpart,newdata=pml_testing)
predictions_testing
```
